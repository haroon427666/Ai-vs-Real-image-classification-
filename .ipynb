{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0abe80f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STAGE 1: AI vs REAL - ConvNeXt-Tiny (4GB VRAM Optimized)\n",
      "============================================================\n",
      "Device: cuda\n",
      "Model: convnext_tiny\n",
      "Image Size: 224x224\n",
      "Batch Size: 16\n",
      "Learning Rate: 5e-05\n",
      "Weight Decay: 0.05\n",
      "Dropout: 0.3\n",
      "Stochastic Depth: 0.1\n",
      "Mixed Precision: True\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "LOADING DATASET\n",
      "============================================================\n",
      "\n",
      "Scanning AI...\n",
      "  Searching for images recursively...\n",
      "  Found 1,479,354 total files\n",
      "  After filtering: 1,479,354 images\n",
      "  Sampling 100,000 images...\n",
      "\n",
      "Scanning Real...\n",
      "  Searching for images recursively...\n",
      "  Found 1,017,384 total files\n",
      "  After filtering: 1,017,384 images\n",
      "  Sampling 100,000 images...\n",
      "\n",
      "Final counts:\n",
      "  AI:   100,000 images\n",
      "  Real: 100,000 images\n",
      "\n",
      "Dataset split:\n",
      "  Train: 144,000 images\n",
      "  Val:   16,000 images\n",
      "  Test:  40,000 images\n",
      "\n",
      "Dataloaders: Train=9000, Val=1000, Test=2500\n",
      "\n",
      "============================================================\n",
      "CREATING CONVNEXT-TINY MODEL (4GB VRAM OPTIMIZED)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/convnext_tiny-983f1562.pth\" to C:\\Users\\-/.cache\\torch\\hub\\checkpoints\\convnext_tiny-983f1562.pth\n",
      "100%|██████████| 109M/109M [01:01<00:00, 1.85MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 28,215,906\n",
      "Trainable parameters: 28,215,906\n",
      "Model size: ~107.64 MB (FP32)\n",
      "With AMP: ~53.82 MB (FP16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:308: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler() if config.USE_AMP else None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Stage 1: AI vs Real Image Classifier - ConvNeXt-Large\n",
    "Optimized for ConvNeXt architecture with modern training techniques\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION - OPTIMIZED FOR 4GB VRAM\n",
    "# ==========================================\n",
    "class Config:\n",
    "    # Paths\n",
    "    DATASET_DIR = r\"E:\\AI\\AI vs Real Dataset\"\n",
    "    AI_DIR = os.path.join(DATASET_DIR, \"AI\")\n",
    "    REAL_DIR = os.path.join(DATASET_DIR, \"Real\")\n",
    "    \n",
    "    # Model - ConvNeXt-Tiny (28M params vs 197M for Large)\n",
    "    MODEL_NAME = \"convnext_tiny\"  # Much lighter!\n",
    "    NUM_CLASSES = 2\n",
    "    IMG_SIZE = 224\n",
    "    \n",
    "    # Training - Optimized for 4GB VRAM\n",
    "    BATCH_SIZE = 16  # Reduced for memory\n",
    "    EPOCHS = 30\n",
    "    LEARNING_RATE = 5e-5\n",
    "    WEIGHT_DECAY = 0.05\n",
    "    DROPOUT_RATE = 0.3  # Reduced dropout\n",
    "    LABEL_SMOOTHING = 0.1\n",
    "    STOCHASTIC_DEPTH = 0.1\n",
    "    \n",
    "    # Data split\n",
    "    TEST_SIZE = 0.2\n",
    "    VAL_SIZE = 0.1\n",
    "    \n",
    "    # System\n",
    "    NUM_WORKERS = 0\n",
    "    PIN_MEMORY = True\n",
    "    PERSISTENT_WORKERS = False\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Checkpointing\n",
    "    SAVE_DIR = \"checkpoints_convnext_tiny\"\n",
    "    \n",
    "    # Early stopping\n",
    "    PATIENCE = 7\n",
    "    \n",
    "    # Mixed precision training\n",
    "    USE_AMP = True  # Critical for 4GB VRAM!\n",
    "\n",
    "config = Config()\n",
    "os.makedirs(config.SAVE_DIR, exist_ok=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STAGE 1: AI vs REAL - ConvNeXt-Tiny (4GB VRAM Optimized)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Device: {config.DEVICE}\")\n",
    "print(f\"Model: {config.MODEL_NAME}\")\n",
    "print(f\"Image Size: {config.IMG_SIZE}x{config.IMG_SIZE}\")\n",
    "print(f\"Batch Size: {config.BATCH_SIZE}\")\n",
    "print(f\"Learning Rate: {config.LEARNING_RATE}\")\n",
    "print(f\"Weight Decay: {config.WEIGHT_DECAY}\")\n",
    "print(f\"Dropout: {config.DROPOUT_RATE}\")\n",
    "print(f\"Stochastic Depth: {config.STOCHASTIC_DEPTH}\")\n",
    "print(f\"Mixed Precision: {config.USE_AMP}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ==========================================\n",
    "# DATA COLLECTION\n",
    "# ==========================================\n",
    "def collect_images_fast(root_dir, max_images=100000):\n",
    "    print(f\"\\nScanning {os.path.basename(root_dir)}...\")\n",
    "    valid_extensions = {'.png', '.jpg', '.jpeg', '.bmp', '.webp'}\n",
    "    exclude_keywords = ['metadata', 'label', 'annotation']\n",
    "    all_images = []\n",
    "    \n",
    "    print(\"  Searching for images recursively...\")\n",
    "    for ext in valid_extensions:\n",
    "        pattern = os.path.join(root_dir, '**', f'*{ext}')\n",
    "        files = glob(pattern, recursive=True)\n",
    "        all_images.extend(files)\n",
    "    \n",
    "    filtered_images = []\n",
    "    for img_path in all_images:\n",
    "        filename = os.path.basename(img_path).lower()\n",
    "        if not any(keyword in filename for keyword in exclude_keywords):\n",
    "            filtered_images.append(img_path)\n",
    "    \n",
    "    print(f\"  Found {len(all_images):,} total files\")\n",
    "    print(f\"  After filtering: {len(filtered_images):,} images\")\n",
    "    \n",
    "    if len(filtered_images) > max_images:\n",
    "        print(f\"  Sampling {max_images:,} images...\")\n",
    "        filtered_images = random.sample(filtered_images, max_images)\n",
    "    \n",
    "    return filtered_images\n",
    "\n",
    "# ==========================================\n",
    "# LOAD DATA\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOADING DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "ai_images = collect_images_fast(config.AI_DIR, max_images=100000)\n",
    "real_images = collect_images_fast(config.REAL_DIR, max_images=100000)\n",
    "\n",
    "print(f\"\\nFinal counts:\")\n",
    "print(f\"  AI:   {len(ai_images):,} images\")\n",
    "print(f\"  Real: {len(real_images):,} images\")\n",
    "\n",
    "all_images = ai_images + real_images\n",
    "labels = [1] * len(ai_images) + [0] * len(real_images)\n",
    "\n",
    "if len(all_images) == 0:\n",
    "    raise ValueError(\"No images found!\")\n",
    "\n",
    "# Shuffle\n",
    "combined = list(zip(all_images, labels))\n",
    "random.shuffle(combined)\n",
    "all_images, labels = zip(*combined)\n",
    "all_images, labels = list(all_images), list(labels)\n",
    "\n",
    "# Split\n",
    "train_imgs, test_imgs, train_lbls, test_lbls = train_test_split(\n",
    "    all_images, labels, test_size=config.TEST_SIZE, random_state=42, stratify=labels\n",
    ")\n",
    "train_imgs, val_imgs, train_lbls, val_lbls = train_test_split(\n",
    "    train_imgs, train_lbls, test_size=config.VAL_SIZE, random_state=42, stratify=train_lbls\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset split:\")\n",
    "print(f\"  Train: {len(train_imgs):,} images\")\n",
    "print(f\"  Val:   {len(val_imgs):,} images\")\n",
    "print(f\"  Test:  {len(test_imgs):,} images\")\n",
    "\n",
    "# ==========================================\n",
    "# DATASET\n",
    "# ==========================================\n",
    "class FastAIDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        try:\n",
    "            with Image.open(path) as img:\n",
    "                img = img.convert(\"RGB\")\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "        except:\n",
    "            img = torch.zeros(3, config.IMG_SIZE, config.IMG_SIZE)\n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "\n",
    "# ==========================================\n",
    "# DATA AUGMENTATION - CONVNEXT OPTIMIZED\n",
    "# ==========================================\n",
    "# ConvNeXt uses stronger augmentation strategies\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.1),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.3),\n",
    "    transforms.RandomGrayscale(p=0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.25, scale=(0.02, 0.2), ratio=(0.3, 3.3))\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ==========================================\n",
    "# DATALOADERS\n",
    "# ==========================================\n",
    "train_dataset = FastAIDataset(train_imgs, train_lbls, transform=train_transform)\n",
    "val_dataset = FastAIDataset(val_imgs, val_lbls, transform=val_transform)\n",
    "test_dataset = FastAIDataset(test_imgs, test_lbls, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=config.NUM_WORKERS, pin_memory=config.PIN_MEMORY)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=config.NUM_WORKERS, pin_memory=config.PIN_MEMORY)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE, shuffle=False,\n",
    "                         num_workers=config.NUM_WORKERS, pin_memory=config.PIN_MEMORY)\n",
    "\n",
    "print(f\"\\nDataloaders: Train={len(train_loader)}, Val={len(val_loader)}, Test={len(test_loader)}\")\n",
    "\n",
    "# ==========================================\n",
    "# CONVNEXT MODEL WITH CUSTOM HEAD\n",
    "# ==========================================\n",
    "class ConvNeXtClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=2, dropout_rate=0.3, model_size='tiny'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load appropriate ConvNeXt model\n",
    "        if model_size == 'tiny':\n",
    "            self.backbone = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\n",
    "        elif model_size == 'small':\n",
    "            self.backbone = models.convnext_small(weights=models.ConvNeXt_Small_Weights.IMAGENET1K_V1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model size: {model_size}\")\n",
    "        \n",
    "        # Get the input features from the classifier\n",
    "        in_features = self.backbone.classifier[2].in_features\n",
    "        \n",
    "        # Replace classifier with custom head\n",
    "        # ConvNeXt output is [B, C, 1, 1], need to flatten first\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Flatten(1),  # Flatten spatial dimensions first\n",
    "            nn.LayerNorm(in_features),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(in_features, 512),  # Reduced from 768\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Dropout(dropout_rate * 0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING CONVNEXT-TINY MODEL (4GB VRAM OPTIMIZED)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model = ConvNeXtClassifier(\n",
    "    num_classes=config.NUM_CLASSES, \n",
    "    dropout_rate=config.DROPOUT_RATE,\n",
    "    model_size='tiny'  # Can change to 'small' if you have headroom\n",
    ")\n",
    "model = model.to(config.DEVICE)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model size: ~{total_params * 4 / (1024**2):.2f} MB (FP32)\")\n",
    "print(f\"With AMP: ~{total_params * 2 / (1024**2):.2f} MB (FP16)\")\n",
    "\n",
    "# ==========================================\n",
    "# LABEL SMOOTHING LOSS\n",
    "# ==========================================\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        confidence = 1.0 - self.smoothing\n",
    "        logprobs = F.log_softmax(pred, dim=-1)\n",
    "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = confidence * nll_loss + self.smoothing * smooth_loss\n",
    "        return loss.mean()\n",
    "\n",
    "criterion = LabelSmoothingCrossEntropy(smoothing=config.LABEL_SMOOTHING)\n",
    "\n",
    "# ==========================================\n",
    "# OPTIMIZER - ADAMW FOR CONVNEXT\n",
    "# ==========================================\n",
    "# ConvNeXt uses AdamW with layer-wise learning rate decay\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config.LEARNING_RATE,\n",
    "    weight_decay=config.WEIGHT_DECAY,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "# Cosine annealing scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    T_max=config.EPOCHS,\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "# Mixed precision scaler\n",
    "scaler = torch.cuda.amp.GradScaler() if config.USE_AMP else None\n",
    "\n",
    "# ==========================================\n",
    "# TRAINING FUNCTIONS\n",
    "# ==========================================\n",
    "def train_epoch(model, loader, criterion, optimizer, scheduler, device, epoch, scaler=None):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch+1}/{config.EPOCHS} [Train]\")\n",
    "    \n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed precision training\n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{running_loss/(pbar.n+1):.4f}',\n",
    "            'acc': f'{100.*correct/total:.2f}%',\n",
    "            'lr': f'{optimizer.param_groups[0][\"lr\"]:.6f}'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, loader, criterion, device, phase=\"Val\"):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=f\"{phase}\")\n",
    "        for images, labels in pbar:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            # Use AMP for inference too\n",
    "            if config.USE_AMP:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{running_loss/(pbar.n+1):.4f}',\n",
    "                'acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    \n",
    "    return epoch_loss, epoch_acc, auc, all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c091cc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Epoch 1/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 1/30 [Train]: 100%|██████████| 9000/9000 [57:14<00:00,  2.62it/s, loss=0.5298, acc=76.25%, lr=0.000050]  \n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [03:40<00:00,  4.54it/s, loss=0.4061, acc=86.38%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.5298, Acc=76.25%\n",
      "  Val:   Loss=0.4061, Acc=86.38%, AUC=0.9393\n",
      "  Generalization Gap: -10.13%\n",
      "  ✓ Best model saved! (Val AUC: 0.9393, Acc: 86.38%)\n",
      "\n",
      "============================================================\n",
      "Epoch 2/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 2/30 [Train]: 100%|██████████| 9000/9000 [56:43<00:00,  2.64it/s, loss=0.4482, acc=83.30%, lr=0.000050]\n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [04:10<00:00,  3.99it/s, loss=0.3743, acc=88.74%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.4482, Acc=83.30%\n",
      "  Val:   Loss=0.3743, Acc=88.74%, AUC=0.9621\n",
      "  Generalization Gap: -5.44%\n",
      "  ✓ Best model saved! (Val AUC: 0.9621, Acc: 88.74%)\n",
      "\n",
      "============================================================\n",
      "Epoch 3/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 3/30 [Train]: 100%|██████████| 9000/9000 [4:56:35<00:00,  1.98s/it, loss=0.4187, acc=85.57%, lr=0.000049]       \n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [03:34<00:00,  4.67it/s, loss=0.3605, acc=89.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.4187, Acc=85.57%\n",
      "  Val:   Loss=0.3605, Acc=89.88%, AUC=0.9640\n",
      "  Generalization Gap: -4.31%\n",
      "  ✓ Best model saved! (Val AUC: 0.9640, Acc: 89.88%)\n",
      "\n",
      "============================================================\n",
      "Epoch 4/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 4/30 [Train]: 100%|██████████| 9000/9000 [15:32:10<00:00,  6.21s/it, loss=0.4023, acc=86.73%, lr=0.000049]        \n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [03:34<00:00,  4.66it/s, loss=0.3663, acc=89.87%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.4023, Acc=86.73%\n",
      "  Val:   Loss=0.3663, Acc=89.87%, AUC=0.9638\n",
      "  Generalization Gap: -3.13%\n",
      "  No improvement (1/7)\n",
      "\n",
      "============================================================\n",
      "Epoch 5/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 5/30 [Train]: 100%|██████████| 9000/9000 [55:22<00:00,  2.71it/s, loss=0.3881, acc=87.91%, lr=0.000048]\n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [05:09<00:00,  3.23it/s, loss=0.3366, acc=91.70%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.3881, Acc=87.91%\n",
      "  Val:   Loss=0.3366, Acc=91.70%, AUC=0.9728\n",
      "  Generalization Gap: -3.79%\n",
      "  ✓ Best model saved! (Val AUC: 0.9728, Acc: 91.70%)\n",
      "\n",
      "============================================================\n",
      "Epoch 6/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 6/30 [Train]: 100%|██████████| 9000/9000 [5:29:06<00:00,  2.19s/it, loss=0.3776, acc=88.61%, lr=0.000047]       \n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [03:19<00:00,  5.01it/s, loss=0.3328, acc=91.71%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.3776, Acc=88.61%\n",
      "  Val:   Loss=0.3328, Acc=91.71%, AUC=0.9733\n",
      "  Generalization Gap: -3.10%\n",
      "  ✓ Best model saved! (Val AUC: 0.9733, Acc: 91.71%)\n",
      "\n",
      "============================================================\n",
      "Epoch 7/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 7/30 [Train]: 100%|██████████| 9000/9000 [1:52:08<00:00,  1.34it/s, loss=0.3683, acc=89.26%, lr=0.000045]     \n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [03:27<00:00,  4.81it/s, loss=0.3885, acc=89.42%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.3683, Acc=89.26%\n",
      "  Val:   Loss=0.3885, Acc=89.42%, AUC=0.9686\n",
      "  Generalization Gap: -0.17%\n",
      "  No improvement (1/7)\n",
      "\n",
      "============================================================\n",
      "Epoch 8/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 8/30 [Train]: 100%|██████████| 9000/9000 [3:02:34<00:00,  1.22s/it, loss=0.3612, acc=89.83%, lr=0.000044]      \n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [03:21<00:00,  4.96it/s, loss=0.3376, acc=91.67%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.3612, Acc=89.83%\n",
      "  Val:   Loss=0.3376, Acc=91.67%, AUC=0.9733\n",
      "  Generalization Gap: -1.84%\n",
      "  ✓ Best model saved! (Val AUC: 0.9733, Acc: 91.67%)\n",
      "\n",
      "============================================================\n",
      "Epoch 9/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 9/30 [Train]: 100%|██████████| 9000/9000 [17:51:50<00:00,  7.15s/it, loss=0.3537, acc=90.36%, lr=0.000042]         \n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [03:23<00:00,  4.92it/s, loss=0.3248, acc=92.71%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.3537, Acc=90.36%\n",
      "  Val:   Loss=0.3248, Acc=92.71%, AUC=0.9762\n",
      "  Generalization Gap: -2.35%\n",
      "  ✓ Best model saved! (Val AUC: 0.9762, Acc: 92.71%)\n",
      "\n",
      "============================================================\n",
      "Epoch 10/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 10/30 [Train]: 100%|██████████| 9000/9000 [2:49:33<00:00,  1.13s/it, loss=0.3457, acc=91.00%, lr=0.000040]      \n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [03:20<00:00,  4.98it/s, loss=0.3311, acc=92.52%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.3457, Acc=91.00%\n",
      "  Val:   Loss=0.3311, Acc=92.52%, AUC=0.9768\n",
      "  Generalization Gap: -1.52%\n",
      "  ✓ Best model saved! (Val AUC: 0.9768, Acc: 92.52%)\n",
      "\n",
      "============================================================\n",
      "Epoch 11/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 11/30 [Train]: 100%|██████████| 9000/9000 [2:57:09<00:00,  1.18s/it, loss=0.3396, acc=91.44%, lr=0.000038]       \n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [03:20<00:00,  4.99it/s, loss=0.3477, acc=91.72%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.3396, Acc=91.44%\n",
      "  Val:   Loss=0.3477, Acc=91.72%, AUC=0.9723\n",
      "  Generalization Gap: -0.28%\n",
      "  No improvement (1/7)\n",
      "\n",
      "============================================================\n",
      "Epoch 12/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 12/30 [Train]: 100%|██████████| 9000/9000 [11:45:05<00:00,  4.70s/it, loss=0.3338, acc=91.92%, lr=0.000035]        \n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [03:18<00:00,  5.03it/s, loss=0.3592, acc=91.56%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.3338, Acc=91.92%\n",
      "  Val:   Loss=0.3592, Acc=91.56%, AUC=0.9732\n",
      "  Generalization Gap: 0.37%\n",
      "  No improvement (2/7)\n",
      "\n",
      "============================================================\n",
      "Epoch 13/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 13/30 [Train]: 100%|██████████| 9000/9000 [9:16:22<00:00,  3.71s/it, loss=0.3281, acc=92.38%, lr=0.000033]       \n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [03:27<00:00,  4.82it/s, loss=0.3757, acc=90.58%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.3281, Acc=92.38%\n",
      "  Val:   Loss=0.3757, Acc=90.58%, AUC=0.9697\n",
      "  Generalization Gap: 1.80%\n",
      "  No improvement (3/7)\n",
      "\n",
      "============================================================\n",
      "Epoch 14/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 14/30 [Train]: 100%|██████████| 9000/9000 [2:53:07<00:00,  1.15s/it, loss=0.3245, acc=92.77%, lr=0.000031]       \n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [03:19<00:00,  5.00it/s, loss=0.3349, acc=92.45%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.3245, Acc=92.77%\n",
      "  Val:   Loss=0.3349, Acc=92.45%, AUC=0.9774\n",
      "  Generalization Gap: 0.32%\n",
      "  ✓ Best model saved! (Val AUC: 0.9774, Acc: 92.45%)\n",
      "\n",
      "============================================================\n",
      "Epoch 15/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 15/30 [Train]: 100%|██████████| 9000/9000 [11:56:53<00:00,  4.78s/it, loss=0.3171, acc=93.22%, lr=0.000028]        \n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [03:21<00:00,  4.95it/s, loss=0.3444, acc=92.61%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.3171, Acc=93.22%\n",
      "  Val:   Loss=0.3444, Acc=92.61%, AUC=0.9772\n",
      "  Generalization Gap: 0.61%\n",
      "  No improvement (1/7)\n",
      "\n",
      "============================================================\n",
      "Epoch 16/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 16/30 [Train]: 100%|██████████| 9000/9000 [48:36<00:00,  3.09it/s, loss=0.3111, acc=93.69%, lr=0.000026]\n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [01:41<00:00,  9.86it/s, loss=0.3553, acc=91.83%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.3111, Acc=93.69%\n",
      "  Val:   Loss=0.3553, Acc=91.83%, AUC=0.9777\n",
      "  Generalization Gap: 1.86%\n",
      "  ✓ Best model saved! (Val AUC: 0.9777, Acc: 91.83%)\n",
      "\n",
      "============================================================\n",
      "Epoch 17/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 17/30 [Train]: 100%|██████████| 9000/9000 [43:14<00:00,  3.47it/s, loss=0.3021, acc=94.34%, lr=0.000023]\n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [57:18<00:00,  3.44s/it, loss=0.3497, acc=92.66%]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.3021, Acc=94.34%\n",
      "  Val:   Loss=0.3493, Acc=92.66%, AUC=0.9773\n",
      "  Generalization Gap: 1.68%\n",
      "  No improvement (1/7)\n",
      "\n",
      "============================================================\n",
      "Epoch 18/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 18/30 [Train]: 100%|██████████| 9000/9000 [45:03<00:00,  3.33it/s, loss=0.2959, acc=94.76%, lr=0.000020]\n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [03:27<00:00,  4.82it/s, loss=0.3489, acc=93.03%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.2959, Acc=94.76%\n",
      "  Val:   Loss=0.3489, Acc=93.03%, AUC=0.9793\n",
      "  Generalization Gap: 1.74%\n",
      "  ✓ Best model saved! (Val AUC: 0.9793, Acc: 93.03%)\n",
      "\n",
      "============================================================\n",
      "Epoch 19/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 19/30 [Train]: 100%|██████████| 9000/9000 [3:50:09<00:00,  1.53s/it, loss=0.2892, acc=95.18%, lr=0.000018]       \n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [03:26<00:00,  4.84it/s, loss=0.3410, acc=93.21%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.2892, Acc=95.18%\n",
      "  Val:   Loss=0.3410, Acc=93.21%, AUC=0.9795\n",
      "  Generalization Gap: 1.97%\n",
      "  ✓ Best model saved! (Val AUC: 0.9795, Acc: 93.21%)\n",
      "\n",
      "============================================================\n",
      "Epoch 20/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 20/30 [Train]: 100%|██████████| 9000/9000 [2:01:27<00:00,  1.24it/s, loss=0.2820, acc=95.65%, lr=0.000016]      \n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [03:24<00:00,  4.90it/s, loss=0.3622, acc=92.51%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.2820, Acc=95.65%\n",
      "  Val:   Loss=0.3622, Acc=92.51%, AUC=0.9780\n",
      "  Generalization Gap: 3.15%\n",
      "  No improvement (1/7)\n",
      "\n",
      "============================================================\n",
      "Epoch 21/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 21/30 [Train]: 100%|██████████| 9000/9000 [2:38:57<00:00,  1.06s/it, loss=0.2760, acc=96.00%, lr=0.000013]     \n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [03:21<00:00,  4.96it/s, loss=0.3428, acc=93.17%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.2760, Acc=96.00%\n",
      "  Val:   Loss=0.3428, Acc=93.17%, AUC=0.9811\n",
      "  Generalization Gap: 2.82%\n",
      "  ✓ Best model saved! (Val AUC: 0.9811, Acc: 93.17%)\n",
      "\n",
      "============================================================\n",
      "Epoch 22/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 22/30 [Train]: 100%|██████████| 9000/9000 [14:49:32<00:00,  5.93s/it, loss=0.2680, acc=96.42%, lr=0.000011]         \n",
      "Val:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:378: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Val: 100%|██████████| 1000/1000 [03:23<00:00,  4.91it/s, loss=0.3456, acc=93.41%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Train: Loss=0.2680, Acc=96.42%\n",
      "  Val:   Loss=0.3456, Acc=93.41%, AUC=0.9795\n",
      "  Generalization Gap: 3.02%\n",
      "  No improvement (1/7)\n",
      "\n",
      "============================================================\n",
      "Epoch 23/30\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 [Train]:   0%|          | 0/9000 [00:00<?, ?it/s]C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_25696\\1356706173.py:329: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 23/30 [Train]:  69%|██████▉   | 6227/9000 [38:00<2:22:35,  3.09s/it, loss=0.2596, acc=96.92%, lr=0.000009]"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# TRAINING LOOP\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [],\n",
    "    'val_loss': [], 'val_acc': [], 'val_auc': []\n",
    "}\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_val_auc = 0.0\n",
    "patience_counter = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(config.EPOCHS):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch {epoch+1}/{config.EPOCHS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, scheduler, config.DEVICE, epoch, scaler\n",
    "    )\n",
    "    \n",
    "    val_loss, val_acc, val_auc, _, _ = validate(\n",
    "        model, val_loader, criterion, config.DEVICE, phase=\"Val\"\n",
    "    )\n",
    "    \n",
    "    # Step scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_auc'].append(val_auc)\n",
    "    \n",
    "    # Calculate generalization gap\n",
    "    gen_gap = train_acc - val_acc\n",
    "    \n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"  Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n",
    "    print(f\"  Val:   Loss={val_loss:.4f}, Acc={val_acc:.2f}%, AUC={val_auc:.4f}\")\n",
    "    print(f\"  Generalization Gap: {gen_gap:.2f}%\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_acc = val_acc\n",
    "        best_val_auc = val_auc\n",
    "        patience_counter = 0\n",
    "        \n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'val_auc': val_auc,\n",
    "            'gen_gap': gen_gap,\n",
    "            'config': {\n",
    "                'model_name': config.MODEL_NAME,\n",
    "                'img_size': config.IMG_SIZE,\n",
    "                'num_classes': config.NUM_CLASSES\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        torch.save(checkpoint, os.path.join(config.SAVE_DIR, 'best_model.pth'))\n",
    "        print(f\"  ✓ Best model saved! (Val AUC: {val_auc:.4f}, Acc: {val_acc:.2f}%)\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"  No improvement ({patience_counter}/{config.PATIENCE})\")\n",
    "    \n",
    "    if patience_counter >= config.PATIENCE:\n",
    "        print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training Complete!\")\n",
    "print(f\"Time: {training_time/60:.2f} minutes\")\n",
    "print(f\"Best Val Acc: {best_val_acc:.2f}%\")\n",
    "print(f\"Best Val AUC: {best_val_auc:.4f}\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc1617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# TEST EVALUATION\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL TEST EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "checkpoint = torch.load(os.path.join(config.SAVE_DIR, 'best_model.pth'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "test_loss, test_acc, test_auc, test_preds, test_labels = validate(\n",
    "    model, test_loader, criterion, config.DEVICE, phase=\"Test\"\n",
    ")\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"  Loss: {test_loss:.4f}\")\n",
    "print(f\"  Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"  AUC: {test_auc:.4f}\")\n",
    "print(f\"  Best Epoch Generalization Gap: {checkpoint['gen_gap']:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, test_preds, target_names=['Real', 'AI']))\n",
    "\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(f\"{'':15} {'Pred Real':>12} {'Pred AI':>12}\")\n",
    "print(f\"{'Actual Real':15} {cm[0][0]:>12} {cm[0][1]:>12}\")\n",
    "print(f\"{'Actual AI':15} {cm[1][0]:>12} {cm[1][1]:>12}\")\n",
    "\n",
    "# ==========================================\n",
    "# SAVE & PLOT\n",
    "# ==========================================\n",
    "with open(os.path.join(config.SAVE_DIR, 'history.json'), 'w') as f:\n",
    "    json.dump(history, f, indent=4)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].plot(history['train_loss'], label='Train', linewidth=2)\n",
    "axes[0, 0].plot(history['val_loss'], label='Val', linewidth=2)\n",
    "axes[0, 0].set_title('Loss', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(history['train_acc'], label='Train', linewidth=2)\n",
    "axes[0, 1].plot(history['val_acc'], label='Val', linewidth=2)\n",
    "axes[0, 1].set_title('Accuracy', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(history['val_auc'], label='Val AUC', linewidth=2, color='green')\n",
    "axes[1, 0].set_title('Validation AUC', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "gen_gaps = [t - v for t, v in zip(history['train_acc'], history['val_acc'])]\n",
    "axes[1, 1].plot(gen_gaps, linewidth=2, color='red')\n",
    "axes[1, 1].set_title('Generalization Gap', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Gap (%)')\n",
    "axes[1, 1].axhline(y=5, color='orange', linestyle='--', label='5% threshold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(config.SAVE_DIR, 'training_curves.png'), dpi=200)\n",
    "print(f\"\\n✓ Results saved to {config.SAVE_DIR}/\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE! ✓\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ==========================================\n",
    "# INFERENCE FUNCTION\n",
    "# ==========================================\n",
    "def predict_image(image_path):\n",
    "    \"\"\"Predict if image is AI or Real\"\"\"\n",
    "    model.eval()\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        img = transform(img).unsqueeze(0).to(config.DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if config.USE_AMP:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    output = model(img)\n",
    "            else:\n",
    "                output = model(img)\n",
    "            \n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            pred = torch.argmax(probs, 1).item()\n",
    "            conf = probs[0][pred].item()\n",
    "        \n",
    "        return {\n",
    "            'prediction': 'AI' if pred == 1 else 'Real',\n",
    "            'confidence': conf * 100,\n",
    "            'prob_real': probs[0][0].item() * 100,\n",
    "            'prob_ai': probs[0][1].item() * 100\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "# Example usage:\n",
    "# result = predict_image('test_image.jpg')\n",
    "# print(f\"Prediction: {result['prediction']} ({result['confidence']:.2f}% confidence)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe083728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179607d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_26348\\3304446760.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded successfully!\n",
      "Classes: ['Ai', 'Real']\n",
      "Total test samples: 2\n",
      "\n",
      "📌 Per-image predictions:\n",
      "🖼 Gemini_Generated_Image_poxdu6poxdu6poxd.png | True: Ai | Predicted: Real\n",
      "🖼 WhatsApp Image 2025-12-18 at 9.14.30 PM (1).jpeg | True: Real | Predicted: Ai\n",
      "\n",
      "🔥 Test Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# 1. DEVICE\n",
    "# ==========================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "torch.backends.cudnn.benchmark = True  # Faster inference\n",
    "\n",
    "# ==========================================\n",
    "# 2. TRANSFORMS (same as training)\n",
    "# ==========================================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "# ==========================================\n",
    "# 3. LOAD MODEL (ConvNeXt tiny, 2 classes)\n",
    "# ==========================================\n",
    "from torchvision.models import convnext_tiny\n",
    "\n",
    "model = convnext_tiny(pretrained=False)\n",
    "model.classifier[2] = nn.Linear(model.classifier[2].in_features, 2)  # AI vs REAL\n",
    "\n",
    "# Load saved checkpoint\n",
    "model_path = r\"C:\\Users\\-\\Desktop\\.ipynb_checkpoints\\Machine_learning\\Deep learning\\deepfake-detector\\ConvNeXt-tiny\\checkpoints_convnext_tiny\\best_model.pth\"\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "\n",
    "state_dict = checkpoint[\"model_state_dict\"]\n",
    "# Remove 'backbone.' prefix if present\n",
    "new_state_dict = {k.replace(\"backbone.\", \"\") if k.startswith(\"backbone.\") else k: v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict, strict=False)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"✅ Model loaded successfully!\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. LOAD TEST DATASET\n",
    "# ==========================================\n",
    "test_dir = r\"C:\\Users\\-\\Desktop\\.ipynb_checkpoints\\Machine_learning\\Deep learning\\deepfake-detector\\Test_images_Ai-Real\"\n",
    "\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "class_names = test_dataset.classes\n",
    "print(\"Classes:\", class_names)\n",
    "print(\"Total test samples:\", len(test_dataset))\n",
    "\n",
    "# ==========================================\n",
    "# 5. PER-IMAGE PREDICTIONS\n",
    "# ==========================================\n",
    "print(\"\\n📌 Per-image predictions:\")\n",
    "for img_path, label in test_dataset.samples:\n",
    "    try:\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "    except:\n",
    "        print(f\"❌ Cannot open: {img_path}\")\n",
    "        continue\n",
    "\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        _, pred = torch.max(output, 1)\n",
    "\n",
    "    true_class = class_names[label]\n",
    "    predicted_class = class_names[pred.item()]\n",
    "    print(f\"🖼 {os.path.basename(img_path)} | True: {true_class} | Predicted: {predicted_class}\")\n",
    "\n",
    "# ==========================================\n",
    "# 6. TEST ACCURACY ON FULL TEST SET\n",
    "# ==========================================\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"\\n🔥 Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# ==========================================\n",
    "# 7. SINGLE IMAGE INFERENCE FUNCTION\n",
    "# ==========================================\n",
    "def predict_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"❌ Cannot read image: {image_path}\")\n",
    "        return\n",
    "\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        _, pred = torch.max(output, 1)\n",
    "\n",
    "    print(f\"🔍 Image: {image_path}\")\n",
    "    print(f\"➡ Prediction: {class_names[pred.item()]}\")\n",
    "\n",
    "# Example usage:\n",
    "# predict_image(r\"C:\\Users\\-\\Desktop\\test_image.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12bd289e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AI vs REAL TEST FOLDER EVALUATION\n",
      "============================================================\n",
      "Model: C:\\Users\\-\\Desktop\\.ipynb_checkpoints\\Machine_learning\\Deep learning\\deepfake-detector\\ConvNeXt-tiny\\checkpoints_convnext_tiny\\best_model.pth\n",
      "Test Folder: C:\\Users\\-\\Desktop\\.ipynb_checkpoints\\Machine_learning\\Deep learning\\deepfake-detector\\Test_images_Ai-Real\n",
      "Device: cuda\n",
      "Inference Runs: 5\n",
      "============================================================\n",
      "LOADING MODEL\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\-\\AppData\\Local\\Temp\\ipykernel_7484\\1436370584.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded successfully!\n",
      "  Training Val Acc: 93.17%\n",
      "  Training Val AUC: 0.9811\n",
      "\n",
      "============================================================\n",
      "LOADING TEST DATA\n",
      "============================================================\n",
      "AI images: 49\n",
      "Real images: 16\n",
      "\n",
      "Total test images: 65\n",
      "\n",
      "============================================================\n",
      "RUNNING EVALUATION\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 65/65 [00:04<00:00, 15.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST RESULTS\n",
      "============================================================\n",
      "\n",
      "Overall Accuracy: 50.77%\n",
      "AI Detection Accuracy: 40.82% (20/49)\n",
      "Real Detection Accuracy: 81.25% (13/16)\n",
      "AUC Score: 0.7041\n",
      "\n",
      "Average Confidence:\n",
      "  Correct predictions: 93.75%\n",
      "  Incorrect predictions: 92.68%\n",
      "\n",
      "Average Uncertainty: ±0.00%\n",
      "\n",
      "============================================================\n",
      "CONFUSION MATRIX\n",
      "============================================================\n",
      "                 Predicted Real    Predicted AI\n",
      "Actual Real                  13               3\n",
      "Actual AI                    29              20\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION REPORT\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.31      0.81      0.45        16\n",
      "          AI       0.87      0.41      0.56        49\n",
      "\n",
      "    accuracy                           0.51        65\n",
      "   macro avg       0.59      0.61      0.50        65\n",
      "weighted avg       0.73      0.51      0.53        65\n",
      "\n",
      "\n",
      "============================================================\n",
      "MISCLASSIFICATION ANALYSIS\n",
      "============================================================\n",
      "False Positives (Real predicted as AI): 3\n",
      "False Negatives (AI predicted as Real): 29\n",
      "\n",
      "✓ Detailed results saved to test_evaluation_results.json\n",
      "\n",
      "============================================================\n",
      "MOST UNCERTAIN PREDICTIONS (Top 10)\n",
      "============================================================\n",
      "1. ✗ download (7).jpg\n",
      "   True: Real, Predicted: AI\n",
      "   Confidence: 66.52% (±0.00%)\n",
      "2. ✗ 45.jpg\n",
      "   True: AI, Predicted: Real\n",
      "   Confidence: 80.04% (±0.00%)\n",
      "3. ✓ 24.jpg\n",
      "   True: AI, Predicted: AI\n",
      "   Confidence: 84.68% (±0.00%)\n",
      "4. ✗ 9.jpg\n",
      "   True: AI, Predicted: Real\n",
      "   Confidence: 90.88% (±0.00%)\n",
      "5. ✓ 36.jpg\n",
      "   True: AI, Predicted: AI\n",
      "   Confidence: 91.20% (±0.00%)\n",
      "6. ✗ 46.jpg\n",
      "   True: AI, Predicted: Real\n",
      "   Confidence: 91.89% (±0.00%)\n",
      "7. ✓ 11.jpg\n",
      "   True: AI, Predicted: AI\n",
      "   Confidence: 91.89% (±0.00%)\n",
      "8. ✗ 2.jpg\n",
      "   True: AI, Predicted: Real\n",
      "   Confidence: 92.03% (±0.00%)\n",
      "9. ✓ 14.jpg\n",
      "   True: AI, Predicted: AI\n",
      "   Confidence: 92.03% (±0.00%)\n",
      "10. ✗ 35.jpg\n",
      "   True: AI, Predicted: Real\n",
      "   Confidence: 92.10% (±0.00%)\n",
      "\n",
      "============================================================\n",
      "WORST MISTAKES (High Confidence but Wrong)\n",
      "============================================================\n",
      "1. ✗ 3.jpg\n",
      "   True: AI, Predicted: Real\n",
      "   Confidence: 95.09%\n",
      "2. ✗ 7.jpg\n",
      "   True: AI, Predicted: Real\n",
      "   Confidence: 95.05%\n",
      "3. ✗ 5.jpg\n",
      "   True: AI, Predicted: Real\n",
      "   Confidence: 95.03%\n",
      "4. ✗ Gemini_Generated_Image_x7wznwx7wznwx7wz.png\n",
      "   True: AI, Predicted: Real\n",
      "   Confidence: 95.01%\n",
      "5. ✗ 4.jpg\n",
      "   True: AI, Predicted: Real\n",
      "   Confidence: 95.00%\n",
      "6. ✗ 21.jpg\n",
      "   True: AI, Predicted: Real\n",
      "   Confidence: 94.97%\n",
      "7. ✗ 10.jpg\n",
      "   True: AI, Predicted: Real\n",
      "   Confidence: 94.94%\n",
      "8. ✗ 18.jpg\n",
      "   True: AI, Predicted: Real\n",
      "   Confidence: 94.88%\n",
      "9. ✗ 15.jpg\n",
      "   True: AI, Predicted: Real\n",
      "   Confidence: 94.87%\n",
      "10. ✗ Gemini_Generated_Image_fg261hfg261hfg26.png\n",
      "   True: AI, Predicted: Real\n",
      "   Confidence: 94.84%\n",
      "\n",
      "============================================================\n",
      "EVALUATION COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Check 'test_evaluation_results.json' for detailed per-image results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Folder Evaluation Script\n",
    "Evaluates model on AI and Real folders with detailed metrics\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==========================================\n",
    "# MODEL DEFINITION\n",
    "# ==========================================\n",
    "class ConvNeXtClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=2, dropout_rate=0.3, model_size='tiny'):\n",
    "        super().__init__()\n",
    "        \n",
    "        if model_size == 'tiny':\n",
    "            self.backbone = models.convnext_tiny(weights=None)\n",
    "        elif model_size == 'small':\n",
    "            self.backbone = models.convnext_small(weights=None)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model size: {model_size}\")\n",
    "        \n",
    "        in_features = self.backbone.classifier[2].in_features\n",
    "        \n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Flatten(1),\n",
    "            nn.LayerNorm(in_features),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Dropout(dropout_rate * 0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# ==========================================\n",
    "# TEST EVALUATOR CLASS\n",
    "# ==========================================\n",
    "class TestFolderEvaluator:\n",
    "    def __init__(self, model_path, device='cuda', img_size=224):\n",
    "        self.device = device\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(\"LOADING MODEL\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Load checkpoint\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = ConvNeXtClassifier(num_classes=2, dropout_rate=0.3, model_size='tiny')\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model = self.model.to(device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        print(f\"✓ Model loaded successfully!\")\n",
    "        print(f\"  Training Val Acc: {checkpoint.get('val_acc', 'N/A'):.2f}%\")\n",
    "        print(f\"  Training Val AUC: {checkpoint.get('val_auc', 'N/A'):.4f}\")\n",
    "        \n",
    "        # Transform (EXACT same as validation)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def load_images_from_folder(self, folder_path, label):\n",
    "        \"\"\"Load all images from a folder\"\"\"\n",
    "        valid_extensions = {'.png', '.jpg', '.jpeg', '.bmp', '.webp'}\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        for file in os.listdir(folder_path):\n",
    "            if os.path.splitext(file)[1].lower() in valid_extensions:\n",
    "                img_path = os.path.join(folder_path, file)\n",
    "                images.append(img_path)\n",
    "                labels.append(label)\n",
    "        \n",
    "        return images, labels\n",
    "    \n",
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"Preprocess single image\"\"\"\n",
    "        try:\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "            return self.transform(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {image_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def evaluate_folder(self, test_folder_path, num_runs=5):\n",
    "        \"\"\"\n",
    "        Evaluate on test folder with AI and Real subfolders\n",
    "        num_runs: Number of inference passes per image for stability\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"LOADING TEST DATA\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Load AI images (label = 1)\n",
    "        ai_folder = os.path.join(test_folder_path, 'AI')\n",
    "        ai_images, ai_labels = self.load_images_from_folder(ai_folder, label=1)\n",
    "        print(f\"AI images: {len(ai_images)}\")\n",
    "        \n",
    "        # Load Real images (label = 0)\n",
    "        real_folder = os.path.join(test_folder_path, 'Real')\n",
    "        real_images, real_labels = self.load_images_from_folder(real_folder, label=0)\n",
    "        print(f\"Real images: {len(real_images)}\")\n",
    "        \n",
    "        # Combine\n",
    "        all_images = ai_images + real_images\n",
    "        all_labels = ai_labels + real_labels\n",
    "        \n",
    "        print(f\"\\nTotal test images: {len(all_images)}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"RUNNING EVALUATION\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        predictions = []\n",
    "        probabilities = []\n",
    "        uncertainties = []\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for img_path in tqdm(all_images, desc=\"Processing images\"):\n",
    "                # Preprocess\n",
    "                img_tensor = self.preprocess_image(img_path)\n",
    "                \n",
    "                if img_tensor is None:\n",
    "                    # If image failed to load, predict randomly\n",
    "                    predictions.append(0)\n",
    "                    probabilities.append([0.5, 0.5])\n",
    "                    uncertainties.append(1.0)\n",
    "                    continue\n",
    "                \n",
    "                img_tensor = img_tensor.unsqueeze(0).to(self.device)\n",
    "                \n",
    "                # Multiple runs for stability\n",
    "                run_probs = []\n",
    "                for _ in range(num_runs):\n",
    "                    output = self.model(img_tensor)\n",
    "                    probs = torch.softmax(output, dim=1)\n",
    "                    run_probs.append(probs.cpu().numpy()[0])\n",
    "                \n",
    "                # Average probabilities\n",
    "                avg_probs = np.mean(run_probs, axis=0)\n",
    "                std_probs = np.std(run_probs, axis=0)\n",
    "                \n",
    "                pred = int(np.argmax(avg_probs))\n",
    "                predictions.append(pred)\n",
    "                probabilities.append(avg_probs)\n",
    "                uncertainties.append(std_probs[pred])\n",
    "        \n",
    "        # Convert to numpy\n",
    "        predictions = np.array(predictions)\n",
    "        probabilities = np.array(probabilities)\n",
    "        all_labels = np.array(all_labels)\n",
    "        uncertainties = np.array(uncertainties)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        self.print_results(all_labels, predictions, probabilities, uncertainties, \n",
    "                          len(ai_images), len(real_images))\n",
    "        \n",
    "        # Save detailed results\n",
    "        self.save_detailed_results(all_images, all_labels, predictions, \n",
    "                                   probabilities, uncertainties)\n",
    "        \n",
    "        return {\n",
    "            'labels': all_labels,\n",
    "            'predictions': predictions,\n",
    "            'probabilities': probabilities,\n",
    "            'uncertainties': uncertainties\n",
    "        }\n",
    "    \n",
    "    def print_results(self, labels, predictions, probabilities, uncertainties, \n",
    "                     num_ai, num_real):\n",
    "        \"\"\"Print detailed results\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"TEST RESULTS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Overall accuracy\n",
    "        accuracy = (predictions == labels).mean() * 100\n",
    "        print(f\"\\nOverall Accuracy: {accuracy:.2f}%\")\n",
    "        \n",
    "        # Per-class accuracy\n",
    "        ai_mask = labels == 1\n",
    "        real_mask = labels == 0\n",
    "        \n",
    "        ai_accuracy = (predictions[ai_mask] == labels[ai_mask]).mean() * 100\n",
    "        real_accuracy = (predictions[real_mask] == labels[real_mask]).mean() * 100\n",
    "        \n",
    "        print(f\"AI Detection Accuracy: {ai_accuracy:.2f}% ({sum(predictions[ai_mask] == 1)}/{num_ai})\")\n",
    "        print(f\"Real Detection Accuracy: {real_accuracy:.2f}% ({sum(predictions[real_mask] == 0)}/{num_real})\")\n",
    "        \n",
    "        # AUC\n",
    "        auc = roc_auc_score(labels, probabilities[:, 1])\n",
    "        print(f\"AUC Score: {auc:.4f}\")\n",
    "        \n",
    "        # Average confidence\n",
    "        correct_mask = predictions == labels\n",
    "        incorrect_mask = predictions != labels\n",
    "        \n",
    "        correct_conf = probabilities[correct_mask, predictions[correct_mask]].mean() * 100\n",
    "        incorrect_conf = probabilities[incorrect_mask, predictions[incorrect_mask]].mean() * 100 if incorrect_mask.sum() > 0 else 0\n",
    "        \n",
    "        print(f\"\\nAverage Confidence:\")\n",
    "        print(f\"  Correct predictions: {correct_conf:.2f}%\")\n",
    "        print(f\"  Incorrect predictions: {incorrect_conf:.2f}%\")\n",
    "        \n",
    "        # Uncertainty analysis\n",
    "        avg_uncertainty = uncertainties.mean() * 100\n",
    "        print(f\"\\nAverage Uncertainty: ±{avg_uncertainty:.2f}%\")\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"CONFUSION MATRIX\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"{'':15} {'Predicted Real':>15} {'Predicted AI':>15}\")\n",
    "        print(f\"{'Actual Real':15} {cm[0][0]:>15} {cm[0][1]:>15}\")\n",
    "        print(f\"{'Actual AI':15} {cm[1][0]:>15} {cm[1][1]:>15}\")\n",
    "        \n",
    "        # Classification Report\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"CLASSIFICATION REPORT\")\n",
    "        print(\"=\"*60)\n",
    "        print(classification_report(labels, predictions, target_names=['Real', 'AI']))\n",
    "        \n",
    "        # Misclassification analysis\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"MISCLASSIFICATION ANALYSIS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        false_positives = sum((labels == 0) & (predictions == 1))\n",
    "        false_negatives = sum((labels == 1) & (predictions == 0))\n",
    "        \n",
    "        print(f\"False Positives (Real predicted as AI): {false_positives}\")\n",
    "        print(f\"False Negatives (AI predicted as Real): {false_negatives}\")\n",
    "    \n",
    "    def save_detailed_results(self, image_paths, labels, predictions, \n",
    "                             probabilities, uncertainties):\n",
    "        \"\"\"Save detailed results to JSON\"\"\"\n",
    "        \n",
    "        results = []\n",
    "        for i, img_path in enumerate(image_paths):\n",
    "            result = {\n",
    "                'image': os.path.basename(img_path),\n",
    "                'true_label': 'AI' if labels[i] == 1 else 'Real',\n",
    "                'predicted_label': 'AI' if predictions[i] == 1 else 'Real',\n",
    "                'correct': bool(labels[i] == predictions[i]),\n",
    "                'confidence': float(probabilities[i][predictions[i]] * 100),\n",
    "                'uncertainty': float(uncertainties[i] * 100),\n",
    "                'prob_real': float(probabilities[i][0] * 100),\n",
    "                'prob_ai': float(probabilities[i][1] * 100)\n",
    "            }\n",
    "            results.append(result)\n",
    "        \n",
    "        # Sort by confidence (lowest first - most uncertain)\n",
    "        results.sort(key=lambda x: x['confidence'])\n",
    "        \n",
    "        output_file = 'test_evaluation_results.json'\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        \n",
    "        print(f\"\\n✓ Detailed results saved to {output_file}\")\n",
    "        \n",
    "        # Print most uncertain predictions\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"MOST UNCERTAIN PREDICTIONS (Top 10)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for i, result in enumerate(results[:10]):\n",
    "            status = \"✓\" if result['correct'] else \"✗\"\n",
    "            print(f\"{i+1}. {status} {result['image']}\")\n",
    "            print(f\"   True: {result['true_label']}, Predicted: {result['predicted_label']}\")\n",
    "            print(f\"   Confidence: {result['confidence']:.2f}% (±{result['uncertainty']:.2f}%)\")\n",
    "        \n",
    "        # Print worst mistakes (high confidence but wrong)\n",
    "        wrong_results = [r for r in results if not r['correct']]\n",
    "        wrong_results.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "        \n",
    "        if wrong_results:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"WORST MISTAKES (High Confidence but Wrong)\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            for i, result in enumerate(wrong_results[:10]):\n",
    "                print(f\"{i+1}. ✗ {result['image']}\")\n",
    "                print(f\"   True: {result['true_label']}, Predicted: {result['predicted_label']}\")\n",
    "                print(f\"   Confidence: {result['confidence']:.2f}%\")\n",
    "\n",
    "# ==========================================\n",
    "# MAIN EXECUTION\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Configuration\n",
    "    MODEL_PATH = r'C:\\Users\\-\\Desktop\\.ipynb_checkpoints\\Machine_learning\\Deep learning\\deepfake-detector\\ConvNeXt-tiny\\checkpoints_convnext_tiny\\best_model.pth'\n",
    "    TEST_FOLDER = r'C:\\Users\\-\\Desktop\\.ipynb_checkpoints\\Machine_learning\\Deep learning\\deepfake-detector\\Test_images_Ai-Real'\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    NUM_RUNS = 5  # Number of inference passes per image\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"AI vs REAL TEST FOLDER EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Model: {MODEL_PATH}\")\n",
    "    print(f\"Test Folder: {TEST_FOLDER}\")\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Inference Runs: {NUM_RUNS}\")\n",
    "    \n",
    "    # Create evaluator\n",
    "    evaluator = TestFolderEvaluator(\n",
    "        model_path=MODEL_PATH,\n",
    "        device=DEVICE,\n",
    "        img_size=224\n",
    "    )\n",
    "    \n",
    "    # Run evaluation\n",
    "    results = evaluator.evaluate_folder(TEST_FOLDER, num_runs=NUM_RUNS)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EVALUATION COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nCheck 'test_evaluation_results.json' for detailed per-image results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92332ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
